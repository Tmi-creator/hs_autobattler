import os
import wandb
from typing import cast
from stable_baselines3.common.callbacks import BaseCallback
from sb3_contrib import MaskablePPO
from hearthstone.env.hs_env import HearthstoneEnv


class GameLoggerCallback(BaseCallback):
    def __init__(self, check_freq: int, log_dir: str, verbose=1):
        super(GameLoggerCallback, self).__init__(verbose)
        self.check_freq = check_freq
        self.log_dir = log_dir
        # –°–æ–∑–¥–∞–µ–º —á–∏—Å—Ç—É—é —Å—Ä–µ–¥—É –¥–ª—è —Ç–µ—Å—Ç–æ–≤
        self.eval_env = HearthstoneEnv()

    def _on_step(self) -> bool:
        if self.n_calls % self.check_freq == 0:
            self._run_simulation()
        return True

    def _run_simulation(self):
        obs, _ = self.eval_env.reset()
        done = False
        truncated = False

        log_lines = [f"# Game Simulation at Step {self.num_timesteps}\n"]

        # –Ø–í–ù–û –ø—Ä–∏–≤–æ–¥–∏–º —Ç–∏–ø –º–æ–¥–µ–ª–∏, —á—Ç–æ–±—ã –∫–æ–¥ –∑–Ω–∞–ª –ø—Ä–æ action_masks
        model = cast(MaskablePPO, self.model)

        while not done and not truncated:
            # –ü–æ–ª—É—á–∞–µ–º –º–∞—Å–∫—É
            masks = self.eval_env.action_masks()

            # –¢–µ–ø–µ—Ä—å –≤—ã–∑—ã–≤–∞–µ–º predict —É MaskablePPO, –≥–¥–µ action_masks –°–£–©–ï–°–¢–í–£–ï–¢
            action, _ = model.predict(obs, action_masks=masks, deterministic=True)

            # –õ–æ–≥–∏—Ä—É–µ–º
            player = self.eval_env.game.players[self.eval_env.my_player_id]
            action_str = self._decode_action(int(action))

            log_lines.append(f"## Turn {self.eval_env.game.turn_count} | HP: {player.health} | Gold: {player.gold}")
            log_lines.append(f"**Board**: {self._format_board(player.board)}")
            log_lines.append(f"**Hand**: {self._format_hand(player.hand)}")
            log_lines.append(f"> **ACTION**: `{action_str}`")
            log_lines.append("---\n")

            obs, reward, done, truncated, info = self.eval_env.step(action)

        # –ò—Ç–æ–≥–∏
        p0 = self.eval_env.game.players[0]
        result = "WIN" if p0.health > 0 else "LOSS/DRAW"
        log_lines.append(f"# GAME OVER: {result}. Final HP: {p0.health}")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        filename = f"game_log_{self.num_timesteps}.md"
        path = os.path.join(self.log_dir, filename)
        with open(path, "w", encoding="utf-8") as f:
            f.write("\n".join(log_lines))

        if wandb.run is not None:
            wandb.save(path)

    def _format_board(self, board):
        return " | ".join([f"{u.card_id}({u.cur_atk}/{u.cur_hp})" for u in board]) if board else "Empty"

    def _format_hand(self, hand):
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –æ–±—Ä–∞—â–µ–Ω–∏–µ –∫ hand (—Ç–∞–º –æ–±—ä–µ–∫—Ç—ã HandCard, –∞ –Ω–µ card_id –Ω–∞–ø—Ä—è–º—É—é)
        return ", ".join([c.unit.card_id if c.unit else c.spell.card_id for c in hand]) if hand else "Empty"

    def _decode_action(self, action):
        if action == 0: return "END_TURN"
        if action == 1: return "ROLL"
        if 2 <= action <= 8: return f"BUY/TARGET_BOARD {action - 2}"
        if 9 <= action <= 15: return f"SELL {action - 9}"
        if 16 <= action <= 25: return f"PLAY {action - 16}"
        if 26 <= action <= 31: return f"SWAP {action - 26}"
        return f"UNKNOWN {action}"


class SelfPlayCallback(BaseCallback):
    """
    –ö–∞–∂–¥—ã–µ `update_freq` —à–∞–≥–æ–≤ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å –∏
    —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –µ—ë –∫–∞–∫ –æ–ø–ø–æ–Ω–µ–Ω—Ç–∞ –¥–ª—è –≤—Å–µ—Ö —Å—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏—è.
    """

    def __init__(self, update_freq: int, model_save_path: str, verbose=1):
        super(SelfPlayCallback, self).__init__(verbose)
        self.update_freq = update_freq
        self.model_save_path = model_save_path
        self.opponent_path = os.path.join(model_save_path, "opponent_temp.zip")

    def _on_step(self) -> bool:
        if self.n_calls % self.update_freq == 0:
            if self.verbose > 0:
                print(f"üîÑ Self-Play: Updating opponent model at step {self.num_timesteps}")

            # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–µ–≥–æ –∞–≥–µ–Ω—Ç–∞
            self.model.save(self.opponent_path)

            # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º –µ–≥–æ –∫–æ–ø–∏—é (–Ω–∞ CPU, —á—Ç–æ–±—ã –Ω–µ –∑–∞–±–∏–≤–∞—Ç—å –ø–∞–º—è—Ç—å)
            # –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º custom_objects, —á—Ç–æ–±—ã –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–∂–µ –µ—Å–ª–∏ –≤–µ—Ä—Å–∏—è –ø–∏—Ç–æ–Ω–∞ —á—É—Ç—å –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è
            opponent = MaskablePPO.load(self.opponent_path, device="cpu")

            # 3. –†–∞—Å—Å—ã–ª–∞–µ–º "–Ω–æ–≤—ã–µ –º–æ–∑–≥–∏" –≤–æ –≤—Å–µ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ —Å—Ä–µ–¥—ã
            # training_env - —ç—Ç–æ –æ–±—ã—á–Ω–æ DummyVecEnv, —É –Ω–µ–≥–æ –µ—Å—Ç—å –º–µ—Ç–æ–¥ env_method
            self.training_env.env_method("set_opponent", opponent)

        return True
